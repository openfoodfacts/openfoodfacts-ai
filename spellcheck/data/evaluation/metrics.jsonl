{
    "metrics": {
        "correction_precision": 0.6157954132860687,
        "precision": 0.5460671040391152,
        "recall": 0.6130502619940764,
        "f1": 0.5481261645609331,
        "f1_beta": 0.5606654306033796,
        "beta": 1.5
    },
    "model": "gpt-3.5-turbo",
    "date": "25/04/2024",
    "benchmark_version": "0.1",
    "benchmark_size": 246
}
{
    "metrics": {
        "correction_precision": 0.4708773774823285,
        "precision": 0.4015515106191568,
        "recall": 0.4976773000111427,
        "f1": 0.40383567007909066,
        "f1_beta": 0.4190921338368768,
        "beta": 1.5
    },
    "model": "claude-3-haiku-20240307",
    "date": "26/04/2024 12:24:10",
    "benchmark_version": "0.1",
    "benchmark_size": 154,
    "comments": [
        "Requests per minutes / day attained",
        "Claude prompt used instead of the basic one. Check Prompt class.",
        "Models overview: https://docs.anthropic.com/claude/docs/models-overview"
    ]
}
{
    "metrics": {
        "correction_precision": 0.5944338318342587,
        "precision": 0.5260807045621008,
        "recall": 0.596854571880158,
        "f1": 0.5248184554561945,
        "f1_beta": 0.5248184554561945,
        "beta": 1.0
    },
    "model": "claude-3-sonnet-20240229",
    "date": "26/04/2024 16:26:57",
    "benchmark_version": "0.1",
    "benchmark_size": 157,
    "comments": [
        "Requests per minutes / day attained",
        "Claude prompt used instead of the basic one. Check Prompt class.",
        "Models overview: https://docs.anthropic.com/claude/docs/models-overview"
    ]
}
{
    "metrics": {
        "correction_precision": 0.4750910003479174,
        "precision": 0.4375529320523882,
        "recall": 0.39780894502721126,
        "f1": 0.3859432020439635,
        "f1_beta": 0.3859432020439635,
        "beta": 1.0
    },
    "model": "claude-3-opus-20240229",
    "date": "26/04/2024 17:24:30",
    "benchmark_version": "0.1",
    "benchmark_size": 110
}
{
    "metrics": {
        "correction_precision": 0.5411694079019865,
        "precision": 0.48657770327832556,
        "recall": 0.56719903250949,
        "f1": 0.5011592204460352,
        "f1_beta": 0.5011592204460352,
        "beta": 1.0
    },
    "model": "gpt-3.5-turbo",
    "date": "29/04/2024 10:27:53",
    "benchmark_version": "0.2",
    "benchmark_size": 243
}
{
    "metrics": {
        "correction_precision": 0.4049266979044456,
        "precision": 0.3226394651253341,
        "recall": 0.46455629400679027,
        "f1": 0.34544526425986594,
        "f1_beta": 0.34544526425986594,
        "beta": 1.0
    },
    "model": "claude-3-haiku-20240307",
    "date": "29/04/2024 11:15:32",
    "benchmark_version": "0.2",
    "benchmark_size": 243
}
{
    "metrics": {
        "correction_precision": 0.43929884170570765,
        "precision": 0.3664067671991553,
        "recall": 0.490016284718536,
        "f1": 0.38329015990790677,
        "f1_beta": 0.38329015990790677,
        "beta": 1.0
    },
    "model": "claude-3-sonnet-20240229",
    "date": "29/04/2024 11:53:34",
    "benchmark_version": "0.2",
    "benchmark_size": 243
}
{
    "metrics": {
        "correction_precision": 0.5161168319349098,
        "precision": 0.4492653556018427,
        "recall": 0.4810378429238078,
        "f1": 0.43541010792459894,
        "f1_beta": 0.43541010792459894,
        "beta": 1.0
    },
    "model": "claude-3-opus-20240229",
    "date": "29/04/2024 13:39:58",
    "benchmark_version": "0.2",
    "benchmark_size": 114
}
{
    "metrics": {
        "correction_precision": 0.4897752620538616,
        "precision": 0.40099172306069253,
        "recall": 0.534792030481331,
        "f1": 0.4297383726744152,
        "f1_beta": 0.4297383726744152,
        "beta": 1.0
    },
    "model": "gpt-4-turbo",
    "date": "29/04/2024 14:14:07",
    "benchmark_version": "0.2",
    "benchmark_size": 243
}
{
    "metrics": {
        "correction_precision": 0.9286563614744352,
        "precision": 0.7455673758865248,
        "recall": 0.8843322818086226,
        "f1": 0.809042809042809,
        "f1_beta": 0.809042809042809,
        "beta": 1.0
    },
    "model": "gpt-3.5-turbo",
    "date": "02/05/2024 18:24:17",
    "benchmark_version": "0.3",
    "benchmark_size": 162
}
{
    "metrics": {
        "correction_precision": 0.8047493403693932,
        "precision": 0.37303149606299213,
        "recall": 0.7846790890269151,
        "f1": 0.5056704469646431,
        "f1_beta": 0.5056704469646431,
        "beta": 1.0
    },
    "model": "claude-3-haiku-20240307",
    "date": "02/05/2024 18:26:09",
    "benchmark_version": "0.3",
    "benchmark_size": 162
}
{
    "metrics": {
        "correction_precision": 0.8128415300546448,
        "precision": 0.42287694974003465,
        "recall": 0.7697160883280757,
        "f1": 0.5458612975391498,
        "f1_beta": 0.5458612975391498,
        "beta": 1.0
    },
    "model": "claude-3-sonnet-20240229",
    "date": "02/05/2024 18:54:52",
    "benchmark_version": "0.3",
    "benchmark_size": 162
}
{
    "metrics": {
        "correction_precision": 0.9258823529411765,
        "precision": 0.769927536231884,
        "recall": 0.8975712777191129,
        "f1": 0.8288639687957094,
        "f1_beta": 0.8288639687957094,
        "beta": 1.0
    },
    "model": "gpt-3.5-turbo",
    "date": "03/05/2024 12:08:41",
    "benchmark_version": "0.3.1",
    "benchmark_size": 162,
    "comments": [
        "Prompt slightly modified to keep '_' around allergens and keeping whitespaces",
        "It happens that whitespaces with % is wrong because an initial percentage were different from the rest. Example: 'sucre 40%, lemon 7,2 %'. LLM struggles with that"
    ]
}
{
    "metrics": {
        "correction_precision": 0.9273809523809524,
        "precision": 0.7533632286995515,
        "recall": 0.8870116156282999,
        "f1": 0.8147429679922406,
        "f1_beta": 0.8147429679922406,
        "beta": 1.0
    },
    "model": "gpt-3.5-turbo",
    "date": "03/05/2024 16:39:28",
    "benchmark_version": "0.3.2",
    "benchmark_size": 162,
    "comments": [
        "Modify prompt to reduce hallucination regarding percentages"
    ]
}
{
    "metrics": {
        "correction_precision": 0.9343575418994413,
        "precision": 0.69921875,
        "recall": 0.8817733990147784,
        "f1": 0.7799564270152505,
        "f1_beta": 0.7799564270152505,
        "beta": 1.0
    },
    "model": "gpt-3.5-turbo",
    "date": "06/05/2024 11:06:35",
    "benchmark_version": "4.2",
    "benchmark_size": 152,
    "comments": [
        "Benchmark modified: no more percentage correction (396 -> 3% no more), if whitespace not necessary ('crabe(...)'), don't add one ('crabe (...)' no more"
    ]
}
