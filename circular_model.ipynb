{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMFmJha31axeab2rGJTB6fz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jagrutiti/openfoodfacts-ai/blob/circular-net-model/circular_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owMPsx7Gt0Cp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "outputId": "21636b52-83b1-4fdf-9708-563d0c868ba6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected model:material_form_model\n",
            "Model Handle at TensorFlow Hub: /content/pre-trained-models/material_form/saved_model/saved_model\n",
            "Labels selected for material_form_model\n",
            "\n",
            "\n",
            "loading model...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-046e4507d9cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loading model...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m \u001b[0mhub_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model loaded!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_hub/module_v2.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(handle, tags, options)\u001b[0m\n\u001b[1;32m    104\u001b[0m         module_path, tags=tags, options=options)\n\u001b[1;32m    105\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m   \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_hub_module_v1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_hub_module_v1\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(export_dir, tags, options)\u001b[0m\n\u001b[1;32m    780\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0mexport_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_partial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"root\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/load.py\u001b[0m in \u001b[0;36mload_partial\u001b[0;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m   saved_model_proto, debug_info = (\n\u001b[0;32m--> 887\u001b[0;31m       loader_impl.parse_saved_model_with_debug_info(export_dir))\n\u001b[0m\u001b[1;32m    888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m   if (len(saved_model_proto.meta_graphs) == 1 and\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model_with_debug_info\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mMissing\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0minfo\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mfine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m   \"\"\"\n\u001b[0;32m---> 57\u001b[0;31m   \u001b[0msaved_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m   debug_info_path = file_io.join(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    114\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     raise IOError(\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;34mf\"SavedModel file does not exist at: {export_dir}{os.path.sep}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;34mf\"{{{constants.SAVED_MODEL_FILENAME_PBTXT}|\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         f\"{constants.SAVED_MODEL_FILENAME_PB}}}\")\n",
            "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: /content/pre-trained-models/material_form/saved_model/saved_model/{saved_model.pbtxt|saved_model.pb}"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pathlib\n",
        "import cv2\n",
        "import logging\n",
        "logging.disable(logging.WARNING)\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "from six import BytesIO\n",
        "from PIL import Image\n",
        "from six.moves.urllib.request import urlopen\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "tf.gfile = tf.io.gfile\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "ALL_MODELS = {\n",
        "'material_model' : '/content/pre-trained-models/material_model/saved_model/saved_model/',\n",
        "'material_form_model' : '/content/pre-trained-models/material_form/saved_model/saved_model',\n",
        "'plastic_model' : '/content/pre-trained-models/plastic_type/saved_model/saved_model/'\n",
        "}\n",
        "\n",
        "# path to an image\n",
        "IMAGES_FOR_TEST = {\n",
        "  'Image1' : 'models/official/projects/waste_identification_ml/pre_processing/config/sample_images/image_2.png'\n",
        "}\n",
        "\n",
        "def normalize_image(image,\n",
        "                    offset=(0.485, 0.456, 0.406),\n",
        "                    scale=(0.229, 0.224, 0.225)):\n",
        "  \"\"\"Normalizes the image to zero mean and unit variance.\"\"\"\n",
        "  with tf.name_scope('normalize_image'):\n",
        "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "    offset = tf.constant(offset)\n",
        "    offset = tf.expand_dims(offset, axis=0)\n",
        "    offset = tf.expand_dims(offset, axis=0)\n",
        "    image -= offset\n",
        "\n",
        "    scale = tf.constant(scale)\n",
        "    scale = tf.expand_dims(scale, axis=0)\n",
        "    scale = tf.expand_dims(scale, axis=0)\n",
        "    image /= scale\n",
        "    return image\n",
        "\n",
        "    \n",
        "def load_image_into_numpy_array(path):\n",
        "  \"\"\"Load an image from file into a numpy array.\n",
        "\n",
        "  Puts image into numpy array to feed into tensorflow graph.\n",
        "  Note that by convention we put it into a numpy array with shape\n",
        "  (height, width, channels), where channels=3 for RGB.\n",
        "\n",
        "  Args:\n",
        "    path: the file path to the image\n",
        "\n",
        "  Returns:\n",
        "    uint8 numpy array with shape (1, h, w, 3)\n",
        "  \"\"\"\n",
        "  image = None\n",
        "  if(path.startswith('http')):\n",
        "    response = urlopen(path)\n",
        "    image_data = response.read()\n",
        "    image_data = BytesIO(image_data)\n",
        "    image = Image.open(image_data)\n",
        "  else:\n",
        "    image_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "    image = Image.open(BytesIO(image_data))\n",
        "\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (1, im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "\n",
        "def build_inputs_for_segmentation(image):\n",
        "  \"\"\"Builds segmentation model inputs for serving.\"\"\"\n",
        "  # Normalizes image with mean and std pixel values.\n",
        "  image = normalize_image(image)\n",
        "  return image\n",
        "\n",
        "  # @title Model Selection { display-mode: \"form\", run: \"auto\" }\n",
        "model_display_name = 'material_form_model' # @param ['material_model','material_form_model','plastic_model']\n",
        "model_handle = ALL_MODELS[model_display_name]\n",
        "\n",
        "print('Selected model:'+ model_display_name)\n",
        "print('Model Handle at TensorFlow Hub: {}'.format(model_handle))\n",
        "\n",
        "# @title Labels for the above model { display-mode: \"form\", run: \"auto\" }\n",
        "\n",
        "if model_display_name == 'material_model':\n",
        "  PATH_TO_LABELS = '/content/models/config/data/material_labels.pbtxt'\n",
        "elif model_display_name == 'material_form_model':\n",
        "  PATH_TO_LABELS = '/content/models/config/data/material_form_labels.pbtxt'\n",
        "elif model_display_name == 'plastic_model':\n",
        "  PATH_TO_LABELS = '/content/models/config/data/plastic_type_labels.pbtxt'\n",
        "\n",
        "print('Labels selected for',model_display_name)\n",
        "print('\\n')\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
        "category_index\n",
        "\n",
        "\n",
        "print('loading model...')\n",
        "hub_model = hub.load(model_handle)\n",
        "print('model loaded!')\n",
        "\n",
        "#@title Image Selection (don't forget to execute the cell!) { display-mode: \"form\"}\n",
        "selected_image = 'Image1' # @param ['Image1']\n",
        "flip_image_horizontally = True #@param {type:\"boolean\"}\n",
        "convert_image_to_grayscale = False #@param {type:\"boolean\"}\n",
        "\n",
        "image_path = IMAGES_FOR_TEST[selected_image]\n",
        "image_np = load_image_into_numpy_array(image_path)\n",
        "\n",
        "# Flip horizontally\n",
        "if(flip_image_horizontally):\n",
        "  image_np[0] = np.fliplr(image_np[0]).copy()\n",
        "\n",
        "# Convert image to grayscale\n",
        "if(convert_image_to_grayscale):\n",
        "  image_np[0] = np.tile(\n",
        "    np.mean(image_np[0], 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
        "\n",
        "print('min:',np.min(image_np[0]), 'max:', np.max(image_np[0]))\n",
        "plt.figure(figsize=(24,32))\n",
        "plt.imshow(image_np[0])\n",
        "plt.show()\n",
        "\n",
        "# get an input size of images on which an Instance Segmentation model is trained\n",
        "hub_model_fn = hub_model.signatures[\"serving_default\"]\n",
        "height=hub_model_fn.structured_input_signature[1]['inputs'].shape[1]\n",
        "width = hub_model_fn.structured_input_signature[1]['inputs'].shape[2]\n",
        "input_size = (height, width)\n",
        "print(input_size)\n",
        "\n",
        "# apply pre-processing functions which were applied during training the model\n",
        "image_np_cp = cv2.resize(image_np[0], input_size[::-1], interpolation = cv2.INTER_AREA)\n",
        "image_np = build_inputs_for_segmentation(image_np_cp)\n",
        "image_np = tf.expand_dims(image_np, axis=0)\n",
        "image_np.get_shape()\n",
        "\n",
        "# display pre-processed image\n",
        "plt.figure(figsize=(24,32))\n",
        "plt.imshow(image_np[0])\n",
        "plt.show()\n",
        "\n",
        "# running inference\n",
        "results = hub_model_fn(image_np)\n",
        "\n",
        "# different object detection models have additional results\n",
        "# all of them are explained in the documentation\n",
        "result = {key:value.numpy() for key,value in results.items()}\n",
        "print(result.keys())\n",
        "\n",
        "# selecting parameters for visualization\n",
        "label_id_offset = 0\n",
        "min_score_thresh =0.6\n",
        "use_normalized_coordinates=True\n",
        "\n",
        "if use_normalized_coordinates:\n",
        "  # Normalizing detection boxes\n",
        "  result['detection_boxes'][0][:,[0,2]] /= height\n",
        "  result['detection_boxes'][0][:,[1,3]] /= width\n",
        "\n",
        "# Visualize detection and masks\n",
        "if 'detection_masks' in result:\n",
        "  # we need to convert np.arrays to tensors\n",
        "  detection_masks = tf.convert_to_tensor(result['detection_masks'][0])\n",
        "  detection_boxes = tf.convert_to_tensor(result['detection_boxes'][0])\n",
        "\n",
        "  detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "            detection_masks, detection_boxes,\n",
        "              image_np.shape[1], image_np.shape[2])\n",
        "  detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
        "                                      np.uint8)\n",
        "\n",
        "  result['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np_cp,\n",
        "      result['detection_boxes'][0],\n",
        "      (result['detection_classes'][0] + label_id_offset).astype(int),\n",
        "      result['detection_scores'][0],\n",
        "      category_index=category_index,\n",
        "      use_normalized_coordinates=use_normalized_coordinates,\n",
        "      max_boxes_to_draw=200,\n",
        "      min_score_thresh=min_score_thresh,\n",
        "      agnostic_mode=False,\n",
        "      instance_masks=result.get('detection_masks_reframed', None),\n",
        "      line_thickness=2)\n",
        "\n",
        "plt.figure(figsize=(24,32))\n",
        "plt.imshow(image_np_cp)\n",
        "plt.show()\n",
        "\n",
        "# collecting all masks and saving\n",
        "\n",
        "mask_count = np.sum(result['detection_scores'][0] >= min_score_thresh)\n",
        "print('Total number of objects found are:', mask_count)\n",
        "mask = np.zeros_like(detection_masks_reframed[0])\n",
        "for i in range(mask_count):\n",
        "  if result['detection_scores'][0][i] >= min_score_thresh:\n",
        "    mask += detection_masks_reframed[i]\n",
        "\n",
        "mask = tf.clip_by_value(mask, 0,1)\n",
        "plt.figure(figsize=(24,32))\n",
        "plt.imshow(mask,cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python --version\n",
        "\n",
        "! python3 -c 'import tensorflow as tf; print(tf.__version__)'  # for Python 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIUWBbeqL91l",
        "outputId": "c36eb55d-e9a9-4da1-d175-12ee39eafad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.15\n",
            "2.9.2\n"
          ]
        }
      ]
    }
  ]
}